from typing import Any, List, Mapping, Optional

from langchain.callbacks.manager import CallbackManagerForLLMRun
from langchain.llms.base import LLM


@property
def _get_model_default_parameters(self):
    return {
        "max_tokens": self.max_tokens,
        "n_predict": self.n_predict,
        "top_k": self.top_k,
        "top_p": self.top_p,
        "temp": self.temp,
        "n_batch": self.n_batch,
        "repeat_penalty": self.repeat_penalty,
        "repeat_last_n": self.repeat_last_n,
    }

@property
def _identifying_params(self) -> Mapping[str, Any]:
    """
    Get all the identifying parameters
    """
    return {
        'model_name' : self.model_name,
        'model_path' : self.model_folder_path,
        'model_parameters': self._get_model_default_parameters
    }

@property
def _llm_type(self) -> str:
    return 'llama'

def _call(self, prompt: str, stop: Optional[List[str]] = None, **kwargs) -> str:
    """
    Args:
        prompt: The prompt to pass into the model.
        stop: A list of strings to stop generation when encountered

    Returns:
        The string generated by the model
    """

    params = {
        **self._get_model_default_parameters,
        **kwargs
    }

    resposne = self.gpt4_model_instance.generate(prompt, **params)
    return resposne
